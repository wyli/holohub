{
  "matlab_gpu_coder": {
    "name": "matlab_gpu_coder",
    "description": "This folder shows how to develop Holoscan applications that uses CUDA code generated by MATLAB GPU Coder. With MATLAB running on a supported system (x86), th...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/matlab_gpu_coder/resources/architecture_diagram.png",
    "tags": [],
    "app_title": "matlab_gpu_coder"
  },
  "Streaming Synthetic Aperture Radar": {
    "name": "Streaming Synthetic Aperture Radar",
    "description": "This application is a demonstration of using Holoscan to construct Synthetic Aperture Radar (SAR) imagery from a data collection. In current form, the data i...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/synthetic_aperture_radar/sar-grab.png",
    "tags": [
      "signal processing",
      "imaging",
      "backprojection",
      "coherent integration",
      "SAR",
      "synthetic aperture",
      "FFT",
      "HoloViz UI"
    ],
    "app_title": "Streaming Synthetic Aperture Radar"
  },
  "VILA Live": {
    "name": "VILA Live",
    "description": "This application demonstrates how to run VILA 1.5 models on live video feed with the possibility of changing the prompt in real time. VILA 1.5 is a family of...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/vila_live/screenshot.png",
    "tags": [
      "computer vision and perception",
      "language model",
      "visual query injection",
      "stream aware inference",
      "large vision model",
      "multimodal model",
      "video processing",
      "interactive"
    ],
    "app_title": "VILA Live"
  },
  "cvcuda_basic": {
    "name": "cvcuda_basic",
    "description": "This application demonstrates seamless interoperability between Holoscan tensors and CV-CUDA tensors. The image processing pipeline is just a simple flip of...",
    "image_url": null,
    "tags": [],
    "app_title": "cvcuda_basic"
  },
  "prohawk_video_replayer": {
    "name": "prohawk_video_replayer",
    "description": "This application utilizes the ProHawk restoration operator along with Holoscan's Video Replayer and Holoviz operators to enhance and restore medical imagery...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/prohawk_video_replayer/screenshot.png",
    "tags": [],
    "app_title": "prohawk_video_replayer"
  },
  "velodyne_lidar_app": {
    "name": "velodyne_lidar_app",
    "description": "In this application we demonstrate how to use Holoscan SDK for low-latency lidar processing. We receive lidar packets from a Velodyne VLP-16 lidar sensor, co...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/velodyne_lidar_app/doc/VLP10HzMontereyHighway.gif",
    "tags": [],
    "app_title": "velodyne_lidar_app"
  },
  "Imaging AI Whole Body Segmentation": {
    "name": "Imaging AI Whole Body Segmentation",
    "description": "This application uses MONAI re-trained TotalSegmentator model to segment 104 body parts from a DICOM series of a CT scan. It is implemented using Holohub DIC...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/imaging_ai_segmentator/resources/segments_3D.png",
    "tags": [
      "healthcare AI",
      "imaging",
      "volumetric reconstruction",
      "interoperable segmentation formats",
      "DICOM seg",
      "MONAI model zoo",
      "total segmentator",
      "radiology imaging"
    ],
    "app_title": "Imaging AI Whole Body Segmentation"
  },
  "Colonoscopy Polyp Segmentation": {
    "name": "Colonoscopy Polyp Segmentation",
    "description": "Full workflow including a generic visualization of segmentation results from a polyp segmentation models. \ud83d\udce6\ufe0f (NGC) Sample App Data for AI Colonoscopy Segment...",
    "image_url": null,
    "tags": [
      "healthcare AI",
      "visualization",
      "polyp mask overlay",
      "contour binary erosion",
      "AJA",
      "colonoscopy",
      "segmentation",
      "HoloViz UI",
      "video processing"
    ],
    "app_title": "Colonoscopy Polyp Segmentation"
  },
  "HoloChat": {
    "name": "HoloChat",
    "description": "HoloChat is an AI-driven chatbot, built on top of a locally hosted Code-Llama model OR a remote NIM API for Llama-3-70b, which acts as developer's copilot in...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/holochat/holochat_demo.gif",
    "tags": [
      "natural language and conversational AI",
      "integration",
      "code context management",
      "documentation aware generation",
      "RAG",
      "NIM",
      "vector database",
      "local LLM"
    ],
    "app_title": "HoloChat"
  },
  "Speech-to-text + Large Language Model": {
    "name": "Speech-to-text + Large Language Model",
    "description": "This application transcribes an audio file using a speech-to-text model (STT), then uses a large language model (LLM) to summarize and generate new relevant...",
    "image_url": null,
    "tags": [
      "healthcare AI",
      "audio",
      "ICD 10 coding automation",
      "clinical transcription workflow",
      "automatic speech recognition",
      "large language model",
      "OpenAI API",
      "radiology imaging"
    ],
    "app_title": "Speech-to-text + Large Language Model"
  },
  "WebRTC Holoviz Server": {
    "name": "WebRTC Holoviz Server",
    "description": "This app generates video frames with user specified content using Holoviz and sends it to a browser using WebRTC. The goal is to show how to remote control o...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/webrtc_holoviz_server/screenshot.png",
    "tags": [
      "computer vision and perception",
      "networking",
      "dynamic geometry rendering",
      "remote pipeline control",
      "WebRTC",
      "visualization",
      "server",
      "HoloViz UI",
      "interactive"
    ],
    "app_title": "WebRTC Holoviz Server"
  },
  "network_radar_pipeline": {
    "name": "network_radar_pipeline",
    "description": "The Network Radar application demonstrates signal processing on data streamed via packets over a network. It showcases the use of both the Advanced Network O...",
    "image_url": null,
    "tags": [],
    "app_title": "network_radar_pipeline"
  },
  "Qt Video Replayer": {
    "name": "Qt Video Replayer",
    "description": "This application demonstrates how to integrate Holoscan with a Qt application. It support displaying the video frames output by a Holoscan operator and chang...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/qt_video_replayer/screenshot.png",
    "tags": [
      "computer vision and perception",
      "integration",
      "dynamic parameter adjustment",
      "operator UI binding",
      "Qt",
      "QML",
      "video processing",
      "visualization",
      "interactive"
    ],
    "app_title": "Qt Video Replayer"
  },
  "WebRTC Video Server": {
    "name": "WebRTC Video Server",
    "description": "This app reads video frames from a file and sends it to a browser using WebRTC. The app starts a web server, the pipeline starts when a browser is connected...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/webrtc_video_server/screenshot.png",
    "tags": [
      "networking and distributed computing",
      "video",
      "frame replay streaming",
      "browser control interface",
      "WebRTC",
      "video processing",
      "client server",
      "communications",
      "video decoding"
    ],
    "app_title": "WebRTC Video Server"
  },
  "FM Radio Automatic Speech Recognition": {
    "name": "FM Radio Automatic Speech Recognition",
    "description": "This project is proof-of-concept demo featuring the combination of real-time, low-level signal processing and deep learning inference. It currently supports...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/fm_asr/docs/images/pipeline_arch.png",
    "tags": [
      "signal processing",
      "audio",
      "FM demodulation",
      "polyphase resampling",
      "automatic speech recognition",
      "signal processing",
      "SDR",
      "gRPC"
    ],
    "app_title": "FM Radio Automatic Speech Recognition"
  },
  "template": {
    "name": "template",
    "description": "This directory contains applications based on the Holoscan Platform. Some applications might require specific hardware and software packages which are descri...",
    "image_url": null,
    "tags": [],
    "app_title": "template"
  },
  "SSD Detection for Endoscopy Tools": {
    "name": "SSD Detection for Endoscopy Tools",
    "description": "We can train the SSD model from NVIDIA DeepLearningExamples repo with any data of our choosing. Here for the purpose of demonstrating the deployment process,...",
    "image_url": null,
    "tags": [
      "healthcare AI",
      "video",
      "surgicaltooltracking",
      "onnx_nhwc_conversion",
      "SSD",
      "detection",
      "video processing",
      "visualization",
      "bounding box"
    ],
    "app_title": "SSD Detection for Endoscopy Tools"
  },
  "basic_networking_ping": {
    "name": "basic_networking_ping",
    "description": "This application takes the existing ping example that runs over Holoscan ports and instead uses the basic network operator to run over a UDP socket. The basi...",
    "image_url": null,
    "tags": [],
    "app_title": "basic_networking_ping"
  },
  "orsi": {
    "name": "orsi",
    "description": "This folder contains three sample applications, please refer to the respective application README for details on assets and use. In and out of body detection...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/orsi/docs/orsi_logo.png",
    "tags": [],
    "app_title": "orsi"
  },
  "XR + Holoviz": {
    "name": "XR + Holoviz",
    "description": "This application demonstrates the integration of Holoscan-XR with Holoviz for extended reality visualization. Run the following command in the top-level Holo...",
    "image_url": null,
    "tags": [
      "XR",
      "OpenXR",
      "Vulkan",
      "3D Visualization"
    ],
    "app_title": "XR + Holoviz"
  },
  "Hyperspectral Image Segmentation": {
    "name": "Hyperspectral Image Segmentation",
    "description": "This application segments endoscopic hyperspectral cubes into 20 organ classes. It visualizes the result together with the RGB image corresponding to the cub...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/hyperspectral_segmentation/screenshot.png",
    "tags": [
      "healthcare AI",
      "visualization",
      "organ classification mapping",
      "hyperspectral cube processing",
      "hyperspectral",
      "segmentation",
      "endoscopy",
      "image processing",
      "visualization"
    ],
    "app_title": "Hyperspectral Image Segmentation"
  },
  "h264": {
    "name": "h264",
    "description": "This folder contains two reference applications that showcases the use of H.264 Encode / Decode operators to read, decode H.264 elementary streams and encode...",
    "image_url": null,
    "tags": [],
    "app_title": "h264"
  },
  "ehr_query_llm": {
    "name": "ehr_query_llm",
    "description": "This reference application demonstrates how Holoscan application developers can build healthcare Gen AI applications that easily interact with EHR systems wi...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/ehr_query_llm/resources/EHR_LLM_Arch.png",
    "tags": [],
    "app_title": "ehr_query_llm"
  },
  "VITA 49 Power Spectral Density (PSD)": {
    "name": "VITA 49 Power Spectral Density (PSD)",
    "description": "The VITA 49 Power Spectral Density (PSD) application takes in a VITA49 data stream from the advanced network operator, then performs an FFT, PSD, and averagi...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/psd_pipeline/imgs/psd_pipeline_diagram.png",
    "tags": [
      "signal processing",
      "networking",
      "i/q scaling",
      "vita49 protocol handling",
      "FFT",
      "PSD",
      "GPUDirect",
      "UDP"
    ],
    "app_title": "VITA 49 Power Spectral Density (PSD)"
  },
  "Depth Anything V2": {
    "name": "Depth Anything V2",
    "description": "This application uses the Depth Anything V2 model for monocular depth estimation. Monocular Depth Estimation refers to the task of predicting the distance of...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/depth_anything_v2/docs/depth.gif",
    "tags": [
      "computer vision and perception",
      "visualization",
      "dynamic colormap generation",
      "edge accelerated inference",
      "monocular depth estimation",
      "interactive",
      "HoloViz UI",
      "video processing"
    ],
    "app_title": "Depth Anything V2"
  },
  "adv_networking_bench": {
    "name": "adv_networking_bench",
    "description": "[!TIP] Review the High Performance Networking tutorial for guided instructions to configure your system and test the Advanced Network library. This is a samp...",
    "image_url": null,
    "tags": [],
    "app_title": "adv_networking_bench"
  },
  "ultrasound_segmentation": {
    "name": "ultrasound_segmentation",
    "description": "This section describes the details of the ultrasound segmentation sample application as well as how to load a custom inference model into the application for...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/ultrasound_segmentation/docs/app_ultrasound.png",
    "tags": [],
    "app_title": "ultrasound_segmentation"
  },
  "dds": {
    "name": "dds",
    "description": "This directory contains applications based on the Holoscan Platform. Some applications might require specific hardware and software packages which are descri...",
    "image_url": null,
    "tags": [],
    "app_title": "dds"
  },
  "Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks": {
    "name": "Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks",
    "description": "This application demonstrates how to run the Florence-2 models on a live video feed with the possibility of changing the task and optional prompt via a QT UI...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/florence-2-vision/demo.gif",
    "tags": [
      "computer vision and perception",
      "video",
      "task switching interface",
      "CUDA HoloViz integration",
      "Qt",
      "multimodal model",
      "detection",
      "segmentation"
    ],
    "app_title": "Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks"
  },
  "realsense_visualizer": {
    "name": "realsense_visualizer",
    "description": "Visualizes frames captured from an Intel RealSense camera. This application requires an Intel RealSense camera. At the top level of the holohub run the follo...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/realsense_visualizer/screenshot.png",
    "tags": [],
    "app_title": "realsense_visualizer"
  },
  "Power Spectral Density with cuNumeric": {
    "name": "Power Spectral Density with cuNumeric",
    "description": "cuNumeric is an drop-in replacement for NumPy that aims to provide a distributed and accelerated drop-in replacement for the NumPy API on top of the Legion r...",
    "image_url": null,
    "tags": [
      "signal processing",
      "distributed",
      "legion runtime",
      "drop in replacement",
      "FFT",
      "PSD"
    ],
    "app_title": "Power Spectral Density with cuNumeric"
  },
  "endoscopy_tool_tracking": {
    "name": "endoscopy_tool_tracking",
    "description": "Digital endoscopy is a key technology for medical screenings and minimally invasive surgeries. Using real-time AI workflows to process and analyze the video...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/endoscopy_tool_tracking/docs/app_endoscopy.png",
    "tags": [],
    "app_title": "endoscopy_tool_tracking"
  },
  "multiai_ultrasound": {
    "name": "multiai_ultrasound",
    "description": "To run multiple inference pipelines in a single application, the Multi AI operators (inference and postprocessor) use APIs from the Holoscan Inference module...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/multiai_ultrasound/docs/workflow_multiai_icardio_app.png",
    "tags": [],
    "app_title": "multiai_ultrasound"
  },
  "pva_video_filter": {
    "name": "pva_video_filter",
    "description": "This application demonstrates the usage of Programmable Vision Accelerator (PVA) within a Holoscan application. It reads a video stream, applies a 2D unsharp...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/pva_video_filter/pva_example.png",
    "tags": [],
    "app_title": "pva_video_filter"
  },
  "Software Defined Radio FM Demodulation": {
    "name": "Software Defined Radio FM Demodulation",
    "description": "As the \"Hello World\" application of software defined radio developers, this demonstration highlights real-time FM demodulation, resampling, and playback on G...",
    "image_url": null,
    "tags": [
      "signal processing",
      "audio",
      "FM demodulation pipeline",
      "GPU accelerated resampling",
      "SDR",
      "signal processing",
      "IQ data",
      "FFT"
    ],
    "app_title": "Software Defined Radio FM Demodulation"
  },
  "volume_rendering": {
    "name": "volume_rendering",
    "description": "This application loads a medical CT scan and renders it in real time at interactive frame rates using ClaraViz (https://github.com/NVIDIA/clara-viz). The app...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/volume_rendering/screenshot.png",
    "tags": [],
    "app_title": "volume_rendering"
  },
  "Real-time Riva ASR to local-LLM": {
    "name": "Real-time Riva ASR to local-LLM",
    "description": "This application streams microphone input to NVIDIA Riva Automatic Speech Recognition (ASR), which once the user specifies they are done speaking, passes the...",
    "image_url": null,
    "tags": [
      "healthcare AI",
      "audio",
      "streaming ASR pipeline",
      "quantized model inference",
      "automatic speech recognition",
      "local LLM",
      "speech to text",
      "radiology imaging"
    ],
    "app_title": "Real-time Riva ASR to local-LLM"
  },
  "vpi_stereo": {
    "name": "vpi_stereo",
    "description": "Demo pipeline showing stereo disparity estimation using the Vision Programming Interface VPI. This pipeline takes video from a stereo camera and uses VPI's s...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/vpi_stereo/images/vpi_stereo.gif",
    "tags": [],
    "app_title": "vpi_stereo"
  },
  "orthorectification_with_optix": {
    "name": "orthorectification_with_optix",
    "description": "This application is an example of utilizing the nvidia OptiX SDK via the PyOptix bindings to create per-frame orthorectified imagery. In this example, one ca...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/orthorectification_with_optix/docs/odm_ortho_pipeline.png",
    "tags": [],
    "app_title": "orthorectification_with_optix"
  },
  "Endoscopy Depth Estimation": {
    "name": "Endoscopy Depth Estimation",
    "description": "This application demonstrates the use of custom components for depth estimation and its rendering using Holoviz with triangle interpolation. \ud83d\udce6\ufe0f (NGC) Sample...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/endoscopy_depth_estimation/screenshot.png",
    "tags": [
      "healthcare AI",
      "networking",
      "endoscopy",
      "monocular depth estimation",
      "CV CUDA",
      "video processing",
      "rendering"
    ],
    "app_title": "Endoscopy Depth Estimation"
  },
  "Real-Time Face and Text Deidentification": {
    "name": "Real-Time Face and Text Deidentification",
    "description": "This sample application demonstrates the use of face and text detection models to do real-time video deidentification. Regions identified to be face or text...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/video_deidentification/docs/video_deid.gif",
    "tags": [
      "computer vision and perception",
      "video",
      "deidentification",
      "overlap suppression",
      "detection",
      "image processing",
      "video processing",
      "bounding box"
    ],
    "app_title": "Real-Time Face and Text Deidentification"
  },
  "CUDA Quantum Variational Quantum Eigensolver (VQE)": {
    "name": "CUDA Quantum Variational Quantum Eigensolver (VQE)",
    "description": "The Variational Quantum Eigensolver (VQE) is a quantum algorithm designed to approximate the ground state energy of quantum systems. This energy, represented...",
    "image_url": null,
    "tags": [
      "tools and other specialized applications",
      "integration",
      "Hamiltonian minimization",
      "parameter optimization",
      "VQE",
      "quantum computing"
    ],
    "app_title": "CUDA Quantum Variational Quantum Eigensolver (VQE)"
  },
  "simple_radar_pipeline": {
    "name": "simple_radar_pipeline",
    "description": "This demonstration walks the developer through building a simple radar signal processing pipeline, targeted towards detecting objects, with Holoscan. In this...",
    "image_url": null,
    "tags": [],
    "app_title": "simple_radar_pipeline"
  },
  "Endoscopy Tool Segmentation from MONAI Model Zoo": {
    "name": "Endoscopy Tool Segmentation from MONAI Model Zoo",
    "description": "This endoscopy tool segmentation application runs the MONAI Endoscopic Tool Segmentation from MONAI Model Zoo. This HoloHub application has been verified on...",
    "image_url": null,
    "tags": [
      "healthcare AI",
      "video",
      "ONNX graphsurgeon",
      "endoscopic instrument analysis",
      "MONAI model zoo",
      "endoscopy",
      "segmentation",
      "video processing"
    ],
    "app_title": "Endoscopy Tool Segmentation from MONAI Model Zoo"
  },
  "openigtlink_3dslicer": {
    "name": "openigtlink_3dslicer",
    "description": "This application demonstrates how to interface Holoscan SDK with 3D Slicer, using the OpenIGTLink protocol. The application is shown in the application graph...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/openigtlink_3dslicer/images/openigtlink_3dslicer_graph.png",
    "tags": [],
    "app_title": "openigtlink_3dslicer"
  },
  "Body Pose Estimation": {
    "name": "Body Pose Estimation",
    "description": "Body pose estimation is a computer vision task that involves recognizing specific points on the human body in images or videos. A model is used to infer the...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/body_pose_estimation/docs/1.png",
    "tags": [
      "computer vision and perception",
      "distributed",
      "tensor axis transformation",
      "keypoint non max suppression",
      "human body pose estimation",
      "DDS",
      "RTI connext",
      "video processing",
      "visualization"
    ],
    "app_title": "Body Pose Estimation"
  },
  "laser_detection_latency": {
    "name": "laser_detection_latency",
    "description": "The laser detection latency application demonstrates the latency differences between two different cameras visually. This folder contains three applications,...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/laser_detection_latency/images/demo.png",
    "tags": [],
    "app_title": "laser_detection_latency"
  },
  "TAO PeopleNet Detection Model on V4L2 Video Stream": {
    "name": "TAO PeopleNet Detection Model on V4L2 Video Stream",
    "description": "Use the TAO PeopleNet available on NGC to detect faces and people in a V4L2 supported video stream. HoloViz is used to draw bounding boxes around the detecti...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/tao_peoplenet/docs/meeting.gif",
    "tags": [
      "computer vision and perception",
      "video",
      "face detection",
      "bounding box filtering",
      "HoloViz UI",
      "video processing",
      "detection"
    ],
    "app_title": "TAO PeopleNet Detection Model on V4L2 Video Stream"
  },
  "high_speed_endoscopy": {
    "name": "high_speed_endoscopy",
    "description": "The high speed endoscopy application showcases how high resolution cameras can be used to capture the scene, post-processed on GPU, and displayed at high fra...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/high_speed_endoscopy/docs/workflow_high_speed_endoscopy_app.png",
    "tags": [],
    "app_title": "high_speed_endoscopy"
  },
  "Basic Pulse Description Word (PDW) Generator": {
    "name": "Basic Pulse Description Word (PDW) Generator",
    "description": "This is a Holoscan pipeline that shows the possibility of using Holoscan as a Pulse Description Word (PDW) generator. This is a process that takes in IQ samp...",
    "image_url": null,
    "tags": [
      "signal processing",
      "radar",
      "pulse description word",
      "spectral threshold detection",
      "FFT",
      "IQ data",
      "UDP",
      "signal processing"
    ],
    "app_title": "Basic Pulse Description Word (PDW) Generator"
  },
  "Yolo Object Detection": {
    "name": "Yolo Object Detection",
    "description": "This project is aiming to provide basic guidance to deploy Yolo-based model to Holoscan SDK as \"Bring Your Own Model\" In this application example, we use the...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/yolo_model_deployment/docs/meeting.gif",
    "tags": [
      "computer vision and perception",
      "video",
      "nhwc nchw conversion",
      "efficientnms_trt integration",
      "yolo detection",
      "video processing",
      "visualization",
      "camera"
    ],
    "app_title": "Yolo Object Detection"
  },
  "multiai_endoscopy": {
    "name": "multiai_endoscopy",
    "description": "In this application, we show how to build a Multi AI application with detection and segmentation models, write postprocessing operators using CuPy and NumPy...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/multiai_endoscopy/images/app_multiai_endoscopy.png",
    "tags": [],
    "app_title": "multiai_endoscopy"
  },
  "endoscopy_out_of_body_detection": {
    "name": "endoscopy_out_of_body_detection",
    "description": "This application performs real-time detection of whether an endoscope is inside or outside the body during endoscopic procedures. For each input frame, the a...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/endoscopy_out_of_body_detection/endoscopy_out_of_body_detection.png",
    "tags": [],
    "app_title": "endoscopy_out_of_body_detection"
  },
  "deltacast_transmitter": {
    "name": "deltacast_transmitter",
    "description": "This application demonstrates the use of videomaster_transmitter to transmit a video stream through a dedicated IO device. This application uses the DELTACAS...",
    "image_url": null,
    "tags": [],
    "app_title": "deltacast_transmitter"
  },
  "stereo_vision": {
    "name": "stereo_vision",
    "description": "A demo pipeline showcasing stereo disparity estimation. This pipeline takes video from a stereo camera and estimates disparity using DNN ESS. The disparity m...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/stereo_vision/images/plants.gif",
    "tags": [],
    "app_title": "stereo_vision"
  },
  "holoviz": {
    "name": "holoviz",
    "description": "This directory contains applications based on the Holoscan Platform. Some applications might require specific hardware and software packages which are descri...",
    "image_url": null,
    "tags": [],
    "app_title": "holoviz"
  },
  "Object Detection using PyTorch Faster R-CNN": {
    "name": "Object Detection using PyTorch Faster R-CNN",
    "description": "This application performs object detection using frcnn resnet50 model from torchvision. The inference is executed using backend in module in Holoscan SDK. is...",
    "image_url": null,
    "tags": [
      "computer vision and perception",
      "video",
      "torchscript inference",
      "GXF tensor conversion",
      "detection",
      "bounding box",
      "video processing",
      "visualization",
      "HoloViz UI"
    ],
    "app_title": "Object Detection using PyTorch Faster R-CNN"
  },
  "distributed": {
    "name": "distributed",
    "description": "This directory contains applications designed to run in distributed environments, allowing them to offload heavy computation to a remote system or the cloud....",
    "image_url": null,
    "tags": [],
    "app_title": "distributed"
  },
  "aja_video_capture": {
    "name": "aja_video_capture",
    "description": "Minimal example to demonstrate the use of the aja source operator to capture device input and stream to holoviz operator. Visit the SDK User Guide to setup t...",
    "image_url": null,
    "tags": [],
    "app_title": "aja_video_capture"
  },
  "WebRTC Video Client": {
    "name": "WebRTC Video Client",
    "description": "This app receives video frames from a web cam connected to a browser and display them on the screen. The app starts a web server, the pipeline starts when a...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/webrtc_video_client/screenshot.png",
    "tags": [
      "networking and distributed computing",
      "video",
      "SDP exchange",
      "ice candidate management",
      "WebRTC",
      "client",
      "camera",
      "visualization",
      "H.264"
    ],
    "app_title": "WebRTC Video Client"
  },
  "Medical Image Viewer in XR": {
    "name": "Medical Image Viewer in XR",
    "description": "We collaborated with Magic Leap on a proof of concept mixed reality viewer for medical imagery built on the Holoscan platform. Medical imagery is one of the...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/volume_rendering_xr/doc/stereo_skeleton.png",
    "tags": [
      "extended reality",
      "visualization",
      "depth conversion",
      "interactive controls",
      "OpenXR",
      "bounding box",
      "HoloViz UI",
      "volume"
    ],
    "app_title": "Medical Image Viewer in XR"
  },
  "nvidia_nim": {
    "name": "nvidia_nim",
    "description": "This directory contains applications based on the Holoscan Platform. Some applications might require specific hardware and software packages which are descri...",
    "image_url": null,
    "tags": [],
    "app_title": "nvidia_nim"
  },
  "SAM 2: Segment Anything in Images and Videos": {
    "name": "SAM 2: Segment Anything in Images and Videos",
    "description": "This application demonstrates how to run SAM2 models on live video feed with the possibility of changing query points in real-time. The application currently...",
    "image_url": "https://raw.githubusercontent.com/nvidia-holoscan/holohub/main/applications/sam2/holohub-sam2.gif",
    "tags": [
      "computer vision and perception",
      "video",
      "mask score optimization",
      "coordinate remapping pipeline",
      "SAM2 model",
      "segmentation",
      "interactive",
      "visualization",
      "camera"
    ],
    "app_title": "SAM 2: Segment Anything in Images and Videos"
  }
}